{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generar_train_test_sets():\n",
    "    train = np.array([])\n",
    "    test = np.array([])\n",
    "    for i in range(k):\n",
    "        if i in tt:\n",
    "            if len(test) == 0:\n",
    "                test = folds[i]\n",
    "            else:\n",
    "                test = np.concatenate((test,folds[i]))\n",
    "        else:\n",
    "            if len(train) == 0:\n",
    "                train = folds[i]\n",
    "            else:\n",
    "                train = np.concatenate((train,folds[i]))\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Leer_Datos(name, delmt = '\\t',head = None):\n",
    "    data = pd.read_csv(name + '.csv', delimiter = delmt)\n",
    "    return data\n",
    "\n",
    "files = [\"diabetes\",\"Enfermedad_Cardiaca\",\"iris\"]\n",
    "f = 1\n",
    "data = Leer_Datos(files[f],'\\t')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sort_values(by=data.columns[-1])\n",
    "raw_data = data.values\n",
    "raw_data_x = raw_data[:,:-1]\n",
    "raw_data_yl = raw_data[:,-1]\n",
    "labels =[raw_data_yl[0]]\n",
    "for ll in raw_data_yl:\n",
    "    if ll not in labels:\n",
    "        labels.append(ll)\n",
    "raw_data_y = np.zeros((len(raw_data_x),len(labels)),dtype=bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "for la in raw_data_yl:\n",
    "    raw_data_y[i,labels.index(la)] = 1\n",
    "    i+=1\n",
    "raw_data_y[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_x = np.array(raw_data_x,dtype=np.float64)\n",
    "def Normalizar_Datos(arraynp):\n",
    "#     last = np.array(arraynp[:,-1])\n",
    "    mean = np.mean(arraynp,0)\n",
    "    standard = np.std(arraynp,0)\n",
    "    for i in range(0,arraynp.shape[0]):\n",
    "        arraynp[i] = np.true_divide((arraynp[i] - mean), standard)\n",
    "#     arraynp[:,-1] = last[:]\n",
    "    return arraynp\n",
    "\n",
    "standard = np.std(raw_data_x,0)\n",
    "raw_data_x = Normalizar_Datos(raw_data_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 13) (303, 2)\n",
      "[False  True]\n",
      "(303, 15)\n",
      "[138]\n",
      "rr 3\n"
     ]
    }
   ],
   "source": [
    "def Crear_k_folds(data, k =3, classes=2):\n",
    "    indexs=[]\n",
    "    for i in range(1,classes+1):\n",
    "        ind = np.where(np.diff(data[:,-i]))\n",
    "        for i in ind[0]:\n",
    "            if i not in indexs:\n",
    "                indexs.append(i)\n",
    "    \n",
    "    indexs= [x+1 for x in indexs]\n",
    "    indexs.sort()\n",
    "    print (indexs)\n",
    "    Groups = np.split(data, indexs)\n",
    "    \n",
    "    Parts =[]\n",
    "    for g in Groups:\n",
    "        tmp = np.array_split(g, k)\n",
    "        for p in tmp:\n",
    "            Parts.append(p)\n",
    "    \n",
    "    res = list()\n",
    "    for i in range(k):\n",
    "        temp = Parts[i]\n",
    "        for j in range(1,classes):\n",
    "            temp = np.concatenate((temp,Parts[i+(k*j)]))\n",
    "\n",
    "        np.random.shuffle(temp)\n",
    "        res.append(temp)\n",
    "    print('rr',len(res))\n",
    "    return res\n",
    "\n",
    "# raw_data_x = Normalizar_Datos(raw_data_x)\n",
    "print(raw_data_x.shape,raw_data_y.shape)\n",
    "print (raw_data_y[-1])\n",
    "num_classes = len(raw_data_y[0])\n",
    "raw_data = np.concatenate((raw_data_x,raw_data_y),axis=1)\n",
    "print(raw_data.shape)\n",
    "raw_folds = Crear_k_folds(raw_data,classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Save_Folds(folds, name, file='/', delt='\\t', classes=2):\n",
    "    for i in range(len(folds)):\n",
    "        X = folds[i][:,:-(classes)]\n",
    "        Y = folds[i][:,-(classes):]\n",
    "        xname = file + name + '_X' + str(i+1) + '.csv'\n",
    "        yname = file + name + '_Y' + str(i+1) + '.csv'\n",
    "        np.savetxt(xname, X, delimiter=delt)\n",
    "        np.savetxt(yname, Y, delimiter=delt)\n",
    "        \n",
    "Save_Folds(raw_folds,'enf_cardiaca','folds/',',',num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sigmoidal(x):\n",
    "    return 1.0 / (1+np.exp(-x))\n",
    "\n",
    "def Derivada_Sigmoidal(x):\n",
    "    return x * (1.0 - x)\n",
    "\n",
    "def Calcular_Funcion_Costo(y_p, y):\n",
    "    a = -np.log(y_p)\n",
    "#     print ('a',a)\n",
    "    b = a * y\n",
    "#     print ('b',b)\n",
    "#     loss = b.sum(axis=1).mean()\n",
    "    loss = b.mean()\n",
    "    return loss\n",
    "\n",
    "def Calcular_Accuracy(X, Y, W):\n",
    "    y_predict = Sigmoidal(X, W).round()#np.rint(Sigmoidal(X, Theta))\n",
    "    count = 0\n",
    "    for y in (Y-y_predict):\n",
    "        if 1 not in y:\n",
    "            count = count + 1\n",
    "    return (count/len(Y)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Forward(X, weights, activations):\n",
    "    A = X\n",
    "    activations[0] = A\n",
    "    for i,w in enumerate(weights):\n",
    "        h = np.dot(A, w)\n",
    "        A = Sigmoidal(h)\n",
    "        activations[i+1] = A\n",
    "    return A, activations\n",
    "\n",
    "def Backward(y_p, y, activations, weights, learning):\n",
    "    delta = (y_p - y) * Derivada_Sigmoidal(activations[-1])\n",
    "    for i in range(1,len(weights)+1):\n",
    "        a = activations[-i-1].reshape(activations[-i-1].shape[0],-1)\n",
    "        d = delta.reshape(delta.shape[0],-1).T\n",
    "        weights[-i] -= learning *(np.dot(a,d))#/bach_size\n",
    "        dd = Derivada_Sigmoidal(activations[-i-1])\n",
    "        delta = dd * np.dot(delta,weights[-i].T)\n",
    "    return weights\n",
    "         \n",
    "def Gradiente_Descendiente(X, Y, weights, iteraciones, learning, activations):\n",
    "    costos = [0] * iteraciones\n",
    "    for i in range(iteraciones):\n",
    "        cost = 0\n",
    "        for j,x in enumerate(X):\n",
    "            y_p, activation = Forward(x, weights, activations)\n",
    "            cost += Calcular_Funcion_Costo(y_p,Y[j])\n",
    "            weights = Backward(y_p, Y[j], activations, weights, learning)\n",
    "        costos[i] = cost / (len(X))\n",
    "    return weights, costos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generar_Pesos(layers):\n",
    "    wei = []\n",
    "    for l in range(len(layers)-1):\n",
    "        w = np.random.rand(layers[l],layers[l+1])\n",
    "        wei.append(w)\n",
    "    return wei\n",
    "\n",
    "def Generar_Activaciones(layers):\n",
    "    act = []\n",
    "    for l in range(len(layers)):\n",
    "        a = np.zeros(layers[l])\n",
    "        act.append(a)\n",
    "    return act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "items = np.array([[random()/2 for _ in range(2)] for _ in range(1000)])\n",
    "targets = np.array([[i[0] + i[1]] for i in items])\n",
    "# targets = np.array([[i[0] + i[1],i[0] - i[1],i[2] * i[3]] for i in items])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 5, 1]\n"
     ]
    }
   ],
   "source": [
    "layers = [items.shape[1]]+[5]+[targets.shape[1]]\n",
    "print (layers)\n",
    "weis = Generar_Pesos(layers)\n",
    "actis = Generar_Activaciones(layers)\n",
    "\n",
    "W,costoss = Gradiente_Descendiente(items,targets,weis,200,0.2,actis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1 0.2] [0.28594068]\n"
     ]
    }
   ],
   "source": [
    "inpu = np.array([0.1,0.2])\n",
    "out,_ = Forward(inpu,W,actis)\n",
    "print(inpu,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x206878472e8>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(np.arange(200),costoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "fx1 = pd.read_csv(\"folds/iris_X1.csv\",delimiter=',',header=None)\n",
    "fx2 = pd.read_csv(\"folds/iris_X2.csv\",delimiter=',',header=None)\n",
    "fx3 = pd.read_csv(\"folds/iris_X3.csv\",delimiter=',',header=None)\n",
    "fy1 = pd.read_csv(\"folds/iris_Y1.csv\",delimiter=',',header=None)\n",
    "fy2 = pd.read_csv(\"folds/iris_Y2.csv\",delimiter=',',header=None)\n",
    "fy3 = pd.read_csv(\"folds/iris_Y3.csv\",delimiter=',',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "fxt = np.concatenate((fx1.values,fx2.values))\n",
    "fyt = np.concatenate((fy1.values,fy2.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 5, 4, 3]\n"
     ]
    }
   ],
   "source": [
    "# 0.005, 300, [4, 3, 6, 3]\n",
    "layers = [fxt.shape[1]]+[5,4]+[fyt.shape[1]]\n",
    "print (layers)\n",
    "weis = Generar_Pesos(layers)\n",
    "# for e in weis:\n",
    "#     print(e.shape)\n",
    "actis = Generar_Activaciones(layers)\n",
    "# for e in actis:\n",
    "#     print(e.shape)\n",
    "W,costoss = Gradiente_Descendiente(fxt,fyt,weis,300,0.4,actis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2068c729400>"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(np.arange(300),costoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calcular_Accuracy(X, Y, W, A):\n",
    "    count = 0\n",
    "    for i,x in enumerate(X):\n",
    "        y_predict,_ = Forward(x,W,A)\n",
    "        y_predict = np.around(y_predict)\n",
    "        yy = Y[i]\n",
    "        y = y_predict - yy\n",
    "#         print (i,y_predict,yy,y)\n",
    "        cc = y_predict == yy\n",
    "#         print(cc,cc.all())\n",
    "        if (y_predict == yy).all():\n",
    "            count+=1\n",
    "#         if np.all(y_predict==y):\n",
    "#             count +=1\n",
    "#     print(count,len(Y))\n",
    "    return (count/len(Y)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0. 1. 0.] [0. 1. 0.] [0. 0. 0.]\n",
      "1 [1. 0. 0.] [1. 0. 0.] [0. 0. 0.]\n",
      "2 [1. 0. 0.] [1. 0. 0.] [0. 0. 0.]\n",
      "3 [0. 0. 1.] [0. 0. 1.] [0. 0. 0.]\n",
      "4 [0. 0. 1.] [0. 0. 1.] [0. 0. 0.]\n",
      "5 [0. 1. 0.] [0. 1. 0.] [0. 0. 0.]\n",
      "6 [0. 1. 0.] [0. 0. 1.] [ 0.  1. -1.]\n",
      "7 [0. 1. 0.] [0. 1. 0.] [0. 0. 0.]\n",
      "8 [0. 1. 0.] [0. 1. 0.] [0. 0. 0.]\n",
      "9 [0. 1. 0.] [0. 1. 0.] [0. 0. 0.]\n",
      "10 [1. 0. 0.] [1. 0. 0.] [0. 0. 0.]\n",
      "11 [0. 0. 1.] [0. 0. 1.] [0. 0. 0.]\n",
      "12 [0. 1. 0.] [0. 1. 0.] [0. 0. 0.]\n",
      "13 [1. 0. 0.] [1. 0. 0.] [0. 0. 0.]\n",
      "14 [1. 0. 0.] [1. 0. 0.] [0. 0. 0.]\n",
      "15 [1. 0. 0.] [1. 0. 0.] [0. 0. 0.]\n",
      "16 [0. 1. 0.] [0. 1. 0.] [0. 0. 0.]\n",
      "17 [0. 1. 0.] [0. 0. 1.] [ 0.  1. -1.]\n",
      "18 [1. 0. 0.] [1. 0. 0.] [0. 0. 0.]\n",
      "19 [0. 1. 0.] [0. 0. 1.] [ 0.  1. -1.]\n",
      "20 [1. 0. 0.] [1. 0. 0.] [0. 0. 0.]\n",
      "21 [0. 0. 1.] [0. 0. 1.] [0. 0. 0.]\n",
      "22 [0. 1. 0.] [0. 1. 0.] [0. 0. 0.]\n",
      "23 [1. 0. 0.] [1. 0. 0.] [0. 0. 0.]\n",
      "24 [1. 0. 0.] [1. 0. 0.] [0. 0. 0.]\n",
      "25 [0. 0. 1.] [0. 0. 1.] [0. 0. 0.]\n",
      "26 [0. 0. 1.] [0. 0. 1.] [0. 0. 0.]\n",
      "27 [0. 1. 0.] [0. 0. 1.] [ 0.  1. -1.]\n",
      "28 [0. 0. 1.] [0. 0. 1.] [0. 0. 0.]\n",
      "29 [1. 0. 0.] [1. 0. 0.] [0. 0. 0.]\n",
      "30 [0. 0. 1.] [0. 0. 1.] [0. 0. 0.]\n",
      "31 [1. 0. 0.] [1. 0. 0.] [0. 0. 0.]\n",
      "32 [0. 0. 1.] [0. 0. 1.] [0. 0. 0.]\n",
      "33 [0. 0. 1.] [0. 0. 1.] [0. 0. 0.]\n",
      "34 [0. 1. 0.] [0. 1. 0.] [0. 0. 0.]\n",
      "35 [0. 1. 0.] [0. 1. 0.] [0. 0. 0.]\n",
      "36 [0. 1. 0.] [0. 1. 0.] [0. 0. 0.]\n",
      "37 [1. 0. 0.] [1. 0. 0.] [0. 0. 0.]\n",
      "38 [0. 1. 0.] [0. 1. 0.] [0. 0. 0.]\n",
      "39 [1. 0. 0.] [1. 0. 0.] [0. 0. 0.]\n",
      "40 [0. 1. 0.] [0. 1. 0.] [0. 0. 0.]\n",
      "41 [0. 1. 0.] [0. 1. 0.] [0. 0. 0.]\n",
      "42 [0. 0. 1.] [0. 0. 1.] [0. 0. 0.]\n",
      "43 [0. 0. 1.] [0. 0. 1.] [0. 0. 0.]\n",
      "44 [0. 1. 0.] [0. 1. 0.] [0. 0. 0.]\n",
      "45 [1. 0. 0.] [1. 0. 0.] [0. 0. 0.]\n",
      "46 [0. 1. 0.] [0. 1. 0.] [0. 0. 0.]\n",
      "47 [1. 0. 0.] [1. 0. 0.] [0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "91.66666666666666"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Calcular_Accuracy(fx3.values,fy3.values,W,actis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimento 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_train_test_sets(name, orden=1, k=3, deli='\\t'):\n",
    "    train_X = np.array([])\n",
    "    train_Y = np.array([])\n",
    "    test_X = np.array([])\n",
    "    test_Y = np.array([])\n",
    "    for i in range(k):\n",
    "        if i+1 == orden:\n",
    "            test_X = pd.read_csv(name+'_X'+str(i+1)+'.csv').values\n",
    "            test_Y = pd.read_csv(name+'_Y'+str(i+1)+'.csv').values\n",
    "        else:\n",
    "            tx = pd.read_csv(name+'_X'+str(i+1)+'.csv').values\n",
    "            ty = pd.read_csv(name+'_Y'+str(i+1)+'.csv').values\n",
    "            if train_X.shape[0] == 0:\n",
    "                train_X = tx\n",
    "                train_Y = ty\n",
    "            else:\n",
    "                train_X = np.concatenate((train_X,tx))\n",
    "                train_Y = np.concatenate((train_Y,ty))\n",
    "            \n",
    "    return train_X, train_Y, test_X, test_Y\n",
    "\n",
    "import random\n",
    "\n",
    "def getNeurons(num_layers=1, neurons=[1]):\n",
    "    lays = []\n",
    "    for i in range(num_layers):\n",
    "        lays.append(random.choice(neurons))\n",
    "    return lays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 3\n",
    "num_hidden_layers = [1,2,3,4]\n",
    "num_neurons_per_l = [3,4,5]\n",
    "tasa_aprendisaje = [0.1,0.2,0.3, 0.4, 0.5]#, 0.05, 0.1, 0.2]\n",
    "num_iteraciones = [200,300, 500, 1000, 2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = len(num_hidden_layers)*len(tasa_aprendisaje)*len(num_iteraciones)\n",
    "namefold = 'folds/iris'\n",
    "# train_X, train_Y, test_X, test_Y = Get_train_test_sets(namefold, 1, k=num_folds, deli=',')\n",
    "LLL = getNeurons(2,[4,3,2])\n",
    "nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== [4, 3, 3] ========\n",
      "======== [4, 4, 3, 3] ========\n",
      "======== [4, 5, 4, 3, 3] ========\n",
      "======== [4, 5, 4, 3, 5, 3] ========\n"
     ]
    }
   ],
   "source": [
    "accuracies = np.empty((nn,3),dtype=np.float32)\n",
    "list_layers = []\n",
    "acc_index=0\n",
    "acc_max = 0\n",
    "best_parameters = (0,0,[])\n",
    "ma_iris = []\n",
    "dma = []\n",
    "for l in num_hidden_layers:\n",
    "    lay = getNeurons(l,num_neurons_per_l)\n",
    "    matrix_ac = np.random.rand(len(tasa_aprendisaje),len(num_iteraciones),num_folds)\n",
    "    for k in range(num_folds):\n",
    "        train_X, train_Y, test_X, test_Y = Get_train_test_sets(namefold, k+1, k=num_folds, deli=',')\n",
    "        layers = [train_X.shape[1]]+lay+[train_Y.shape[1]]\n",
    "        for i,t in enumerate(tasa_aprendisaje):\n",
    "            for j,itr in enumerate(num_iteraciones):\n",
    "                weigths = Generar_Pesos(layers)\n",
    "                activations = Generar_Activaciones(layers)\n",
    "                new_Weigths, _ = Gradiente_Descendiente(train_X, train_Y, weigths, itr, t, activations)\n",
    "\n",
    "                matrix_ac[i,j,k] = Calcular_Accuracy(test_X,test_Y,new_Weigths,activations)\n",
    "    ma_iris.append((layers,np.mean(matrix_ac,axis=2)))\n",
    "#     dma.append(pd.DataFrame(data = ma[-1], index= tasa_aprendisaje, columns = num_iteraciones))\n",
    "    print('========',layers,'========')\n",
    "# print(ma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([4, 4, 3], array([[85.78723404, 85.82978723],\n",
       "         [87.16312057, 93.95744681],\n",
       "         [93.29078014, 95.33333333]])),\n",
       " ([4, 4, 5, 3], array([[86.36879433, 96.66666667],\n",
       "         [97.33333333, 96.66666667],\n",
       "         [96.66666667, 96.62411348]]))]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.1, 1000, [4, 4, 3, 3]) 98.0\n"
     ]
    }
   ],
   "source": [
    "max_acc = 0\n",
    "parametrs = (0,0,[])\n",
    "\n",
    "for ar,M in ma_iris:\n",
    "    for i in range(len(M)):\n",
    "        for j in range(len(M[0])):\n",
    "            if M[i,j] > max_acc:\n",
    "                max_acc = M[i,j]\n",
    "                parametrs = (tasa_aprendisaje[i],num_iteraciones[j],ar)\n",
    "                MM_ = M\n",
    "\n",
    "print (parametrs,max_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>200</th>\n",
       "      <th>300</th>\n",
       "      <th>500</th>\n",
       "      <th>1000</th>\n",
       "      <th>2000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>87.290780</td>\n",
       "      <td>94.539007</td>\n",
       "      <td>95.957447</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>96.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.2</th>\n",
       "      <td>97.333333</td>\n",
       "      <td>97.333333</td>\n",
       "      <td>97.333333</td>\n",
       "      <td>95.957447</td>\n",
       "      <td>97.290780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3</th>\n",
       "      <td>97.333333</td>\n",
       "      <td>97.333333</td>\n",
       "      <td>95.872340</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>93.787234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>98.000000</td>\n",
       "      <td>96.666667</td>\n",
       "      <td>93.787234</td>\n",
       "      <td>93.787234</td>\n",
       "      <td>93.744681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>95.333333</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>93.120567</td>\n",
       "      <td>95.205674</td>\n",
       "      <td>94.539007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          200        300        500        1000       2000\n",
       "0.1  87.290780  94.539007  95.957447  98.000000  96.666667\n",
       "0.2  97.333333  97.333333  97.333333  95.957447  97.290780\n",
       "0.3  97.333333  97.333333  95.872340  98.000000  93.787234\n",
       "0.4  98.000000  96.666667  93.787234  93.787234  93.744681\n",
       "0.5  95.333333  96.000000  93.120567  95.205674  94.539007"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame(data = MM_, index= tasa_aprendisaje, columns = num_iteraciones)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 3\n",
    "num_hidden_layers = [1,2,3,4]\n",
    "num_neurons_per_l = [4,5,6,7]\n",
    "tasa_aprendisaje = [0.1,0.2,0.3, 0.4, 0.5]#, 0.05, 0.1, 0.2]\n",
    "num_iteraciones = [200,300, 500, 1000, 2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = len(num_hidden_layers)*len(tasa_aprendisaje)*len(num_iteraciones)\n",
    "namefold = 'folds/enf_cardiaca'\n",
    "# train_X, train_Y, test_X, test_Y = Get_train_test_sets(namefold, 1, k=num_folds, deli=',')\n",
    "LLL = getNeurons(2,[4,3,2])\n",
    "nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== [13, 5, 2] ========\n",
      "======== [13, 7, 5, 2] ========\n",
      "======== [13, 6, 4, 6, 2] ========\n",
      "======== [13, 6, 5, 6, 7, 2] ========\n"
     ]
    }
   ],
   "source": [
    "accuracies = np.empty((nn,3),dtype=np.float32)\n",
    "list_layers = []\n",
    "acc_index=0\n",
    "acc_max = 0\n",
    "best_parameters = (0,0,[])\n",
    "ma_card = []\n",
    "dma = []\n",
    "for l in num_hidden_layers:\n",
    "    lay = getNeurons(l,num_neurons_per_l)\n",
    "    matrix_ac = np.random.rand(len(tasa_aprendisaje),len(num_iteraciones),num_folds)\n",
    "    for k in range(num_folds):\n",
    "        train_X, train_Y, test_X, test_Y = Get_train_test_sets(namefold, k+1, k=num_folds, deli=',')\n",
    "        layers = [train_X.shape[1]]+lay+[train_Y.shape[1]]\n",
    "        for i,t in enumerate(tasa_aprendisaje):\n",
    "            for j,itr in enumerate(num_iteraciones):\n",
    "                weigths = Generar_Pesos(layers)\n",
    "                activations = Generar_Activaciones(layers)\n",
    "                new_Weigths, _ = Gradiente_Descendiente(train_X, train_Y, weigths, itr, t, activations)\n",
    "\n",
    "                matrix_ac[i,j,k] = Calcular_Accuracy(test_X,test_Y,new_Weigths,activations)\n",
    "    ma_card.append((layers,np.mean(matrix_ac,axis=2)))\n",
    "#     dma.append(pd.DataFrame(data = ma[-1], index= tasa_aprendisaje, columns = num_iteraciones))\n",
    "    print('========',layers,'========')\n",
    "# print(ma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.1, 200, [13, 7, 5, 2]) 83.66666666666667\n"
     ]
    }
   ],
   "source": [
    "max_acc = 0\n",
    "parametrs = (0,0,[])\n",
    "for ar,M in ma_card:\n",
    "    for i in range(len(M)):\n",
    "        for j in range(len(M[0])):\n",
    "            if M[i,j] > max_acc:\n",
    "                max_acc = M[i,j]\n",
    "                parametrs = (tasa_aprendisaje[i],num_iteraciones[j],ar)\n",
    "                MM_=M\n",
    "print (parametrs, max_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>200</th>\n",
       "      <th>300</th>\n",
       "      <th>500</th>\n",
       "      <th>1000</th>\n",
       "      <th>2000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>83.666667</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>80.666667</td>\n",
       "      <td>78.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.2</th>\n",
       "      <td>80.333333</td>\n",
       "      <td>81.666667</td>\n",
       "      <td>76.666667</td>\n",
       "      <td>80.333333</td>\n",
       "      <td>77.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3</th>\n",
       "      <td>78.666667</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>78.333333</td>\n",
       "      <td>78.666667</td>\n",
       "      <td>77.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>79.666667</td>\n",
       "      <td>80.333333</td>\n",
       "      <td>79.666667</td>\n",
       "      <td>75.666667</td>\n",
       "      <td>76.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>81.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>81.333333</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>79.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          200        300        500        1000       2000\n",
       "0.1  83.666667  81.000000  79.000000  80.666667  78.666667\n",
       "0.2  80.333333  81.666667  76.666667  80.333333  77.666667\n",
       "0.3  78.666667  80.000000  78.333333  78.666667  77.000000\n",
       "0.4  79.666667  80.333333  79.666667  75.666667  76.333333\n",
       "0.5  81.000000  77.000000  81.333333  77.000000  79.666667"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame(data = MM_, index= tasa_aprendisaje, columns = num_iteraciones)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1a6fda9d278>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_X, train_Y, test_X, test_Y = Get_train_test_sets(namefold, k+1, k=num_folds, deli=',')\n",
    "layers = [train_X.shape[1]]+[7,5]+[train_Y.shape[1]]\n",
    "weigths = Generar_Pesos(layers)\n",
    "activations = Generar_Activaciones(layers)\n",
    "itera=1000\n",
    "new_Weigths, loss = Gradiente_Descendiente(train_X, train_Y, weigths, itera, 0.1, activations)\n",
    "\n",
    "plt.scatter(np.arange(itera),loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimento 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4) (150,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "irisX = iris.data\n",
    "irisy = iris.target\n",
    "print(irisX.shape,irisy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toSVM(train, test):\n",
    "#     print((train.shape[0],0))\n",
    "    tr = np.zeros((train.shape[0],))\n",
    "    ts = np.zeros((test.shape[0],))\n",
    "#     print (tr.shape)\n",
    "    \n",
    "    for i,r in enumerate(train):\n",
    "#         print(i,r,np.where(r==1)[0])\n",
    "        tr[i] = np.where(r==1)[0]\n",
    "    for i,s in enumerate(test):\n",
    "        ts[i] = np.where(s==1)[0]\n",
    "#     print (tr)\n",
    "    return tr,ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[1.        , 0.9       , 1.        ],\n",
       "        [0.98      , 0.92      , 1.        ],\n",
       "        [0.98      , 0.9       , 1.        ],\n",
       "        [1.        , 0.9       , 1.        ],\n",
       "        [1.        , 0.9       , 1.        ],\n",
       "        [1.        , 0.9       , 1.        ],\n",
       "        [1.        , 0.92      , 1.        ]],\n",
       "\n",
       "       [[0.88      , 0.88      , 0.89361702],\n",
       "        [0.96      , 0.92      , 0.89361702],\n",
       "        [0.98      , 0.94      , 0.91489362],\n",
       "        [0.98      , 0.94      , 0.93617021],\n",
       "        [0.98      , 0.94      , 0.93617021],\n",
       "        [0.98      , 0.96      , 0.93617021],\n",
       "        [0.98      , 0.92      , 0.95744681]],\n",
       "\n",
       "       [[0.92      , 0.9       , 1.        ],\n",
       "        [0.9       , 0.88      , 1.        ],\n",
       "        [0.9       , 0.84      , 0.9787234 ],\n",
       "        [0.84      , 0.78      , 0.9787234 ],\n",
       "        [0.82      , 0.76      , 0.9787234 ],\n",
       "        [0.8       , 0.76      , 0.9787234 ],\n",
       "        [0.78      , 0.88      , 0.95744681]],\n",
       "\n",
       "       [[0.96      , 0.92      , 0.95744681],\n",
       "        [1.        , 0.92      , 0.9787234 ],\n",
       "        [1.        , 0.92      , 1.        ],\n",
       "        [0.98      , 0.92      , 1.        ],\n",
       "        [0.98      , 0.9       , 1.        ],\n",
       "        [0.98      , 0.92      , 0.9787234 ],\n",
       "        [1.        , 0.96      , 1.        ]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_kernel = ['linear','poly','sigmoid','rbf']\n",
    "parameter_C = [0.5,1.0,1.5,2.0,2.5,3.0,10.0]#[1.0,0.5,1.5]\n",
    "matrix_ac_iris = np.random.rand(len(type_kernel),len(parameter_C),3)\n",
    "namefold = 'folds/iris'\n",
    "for k in range(num_folds):\n",
    "    train_X, train_Y, test_X, test_Y = Get_train_test_sets(namefold, k+1, k=num_folds, deli=',')\n",
    "    train_Y, test_Y = toSVM(train_Y, test_Y)\n",
    "#     print(train_Y)\n",
    "    for i,ke in enumerate(type_kernel):\n",
    "        for j,c in enumerate(parameter_C):\n",
    "            clf = svm.SVC(C=c, kernel = ke)\n",
    "#             print (train_X.shape,train_Y.shape)\n",
    "            clf.fit(train_X, train_Y)\n",
    "            matrix_ac_iris[i,j,k] = accuracy_score(test_Y,clf.predict(test_X))\n",
    "        \n",
    "matrix_ac_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 7, 3)\n",
      "Mayor accuracy promedio con: rbf 10.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.5</th>\n",
       "      <th>1.0</th>\n",
       "      <th>1.5</th>\n",
       "      <th>2.0</th>\n",
       "      <th>2.5</th>\n",
       "      <th>3.0</th>\n",
       "      <th>10.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>linear</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.973333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poly</th>\n",
       "      <td>0.884539</td>\n",
       "      <td>0.924539</td>\n",
       "      <td>0.944965</td>\n",
       "      <td>0.952057</td>\n",
       "      <td>0.952057</td>\n",
       "      <td>0.958723</td>\n",
       "      <td>0.952482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigmoid</th>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.926667</td>\n",
       "      <td>0.906241</td>\n",
       "      <td>0.866241</td>\n",
       "      <td>0.852908</td>\n",
       "      <td>0.846241</td>\n",
       "      <td>0.872482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rbf</th>\n",
       "      <td>0.945816</td>\n",
       "      <td>0.966241</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.959574</td>\n",
       "      <td>0.986667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0.5       1.0       1.5       2.0       2.5       3.0       10.0\n",
       "linear   0.966667  0.966667  0.960000  0.966667  0.966667  0.966667  0.973333\n",
       "poly     0.884539  0.924539  0.944965  0.952057  0.952057  0.958723  0.952482\n",
       "sigmoid  0.940000  0.926667  0.906241  0.866241  0.852908  0.846241  0.872482\n",
       "rbf      0.945816  0.966241  0.973333  0.966667  0.960000  0.959574  0.986667"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(matrix_ac_iris.shape)\n",
    "matrix_ac_iris = np.mean(matrix_ac_iris,axis=2)\n",
    "parametros = (0,0)\n",
    "for ta in  range(len(type_kernel)):\n",
    "    for itr in range(len(parameter_C)):\n",
    "        if(matrix_ac_iris[ta,itr] > matrix_ac_iris[parametros[0],parametros[1]]):\n",
    "            parametros = (ta, itr)\n",
    "\n",
    "df1 = pd.DataFrame(data = matrix_ac_iris, index= type_kernel, columns = parameter_C)\n",
    "print(\"Mayor accuracy promedio con:\",type_kernel[parametros[0]],parameter_C[parametros[1]])\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\jhere\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0.85, 0.83, 0.82],\n",
       "        [0.85, 0.82, 0.81],\n",
       "        [0.85, 0.82, 0.82],\n",
       "        [0.85, 0.82, 0.82],\n",
       "        [0.85, 0.82, 0.82],\n",
       "        [0.85, 0.82, 0.82],\n",
       "        [0.86, 0.83, 0.82]],\n",
       "\n",
       "       [[0.77, 0.76, 0.77],\n",
       "        [0.83, 0.8 , 0.8 ],\n",
       "        [0.85, 0.79, 0.81],\n",
       "        [0.86, 0.78, 0.8 ],\n",
       "        [0.86, 0.8 , 0.79],\n",
       "        [0.85, 0.81, 0.79],\n",
       "        [0.81, 0.8 , 0.75]],\n",
       "\n",
       "       [[0.82, 0.8 , 0.84],\n",
       "        [0.84, 0.84, 0.82],\n",
       "        [0.83, 0.82, 0.81],\n",
       "        [0.84, 0.83, 0.83],\n",
       "        [0.83, 0.84, 0.81],\n",
       "        [0.84, 0.8 , 0.8 ],\n",
       "        [0.82, 0.8 , 0.86]],\n",
       "\n",
       "       [[0.87, 0.81, 0.84],\n",
       "        [0.85, 0.84, 0.81],\n",
       "        [0.84, 0.85, 0.83],\n",
       "        [0.83, 0.85, 0.8 ],\n",
       "        [0.83, 0.85, 0.79],\n",
       "        [0.82, 0.83, 0.77],\n",
       "        [0.8 , 0.8 , 0.77]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_kernel = ['linear','poly','sigmoid','rbf']\n",
    "parameter_C = [0.5,1.0,1.5,2.0,2.5,3.0,10.0]#[1.0,0.5,1.5]\n",
    "matrix_ac_card = np.random.rand(len(type_kernel),len(parameter_C),3)\n",
    "namefold = 'folds/enf_cardiaca'\n",
    "for k in range(num_folds):\n",
    "    train_X, train_Y, test_X, test_Y = Get_train_test_sets(namefold, k+1, k=num_folds, deli=',')\n",
    "    train_Y, test_Y = toSVM(train_Y, test_Y)\n",
    "#     print(train_Y)\n",
    "    for i,ke in enumerate(type_kernel):\n",
    "        for j,c in enumerate(parameter_C):\n",
    "            clf = svm.SVC(C=c, kernel = ke)\n",
    "#             print (train_X.shape,train_Y.shape)\n",
    "            clf.fit(train_X, train_Y)\n",
    "            matrix_ac_card[i,j,k] = accuracy_score(test_Y,clf.predict(test_X))\n",
    "        \n",
    "matrix_ac_card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 7, 3)\n",
      "Mayor accuracy promedio con: rbf 0.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.5</th>\n",
       "      <th>1.0</th>\n",
       "      <th>1.5</th>\n",
       "      <th>2.0</th>\n",
       "      <th>2.5</th>\n",
       "      <th>3.0</th>\n",
       "      <th>10.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>linear</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.836667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poly</th>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.813333</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.786667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigmoid</th>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.813333</td>\n",
       "      <td>0.826667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rbf</th>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.823333</td>\n",
       "      <td>0.806667</td>\n",
       "      <td>0.790000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0.5       1.0       1.5       2.0       2.5       3.0       10.0\n",
       "linear   0.833333  0.826667  0.830000  0.830000  0.830000  0.830000  0.836667\n",
       "poly     0.766667  0.810000  0.816667  0.813333  0.816667  0.816667  0.786667\n",
       "sigmoid  0.820000  0.833333  0.820000  0.833333  0.826667  0.813333  0.826667\n",
       "rbf      0.840000  0.833333  0.840000  0.826667  0.823333  0.806667  0.790000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(matrix_ac_card.shape)\n",
    "matrix_ac_card = np.mean(matrix_ac_card,axis=2)\n",
    "parametros = (0,0)\n",
    "for ta in  range(len(type_kernel)):\n",
    "    for itr in range(len(parameter_C)):\n",
    "        if(matrix_ac_card[ta,itr] > matrix_ac_card[parametros[0],parametros[1]]):\n",
    "            parametros = (ta, itr)\n",
    "\n",
    "df1 = pd.DataFrame(data = matrix_ac_card, index= type_kernel, columns = parameter_C)\n",
    "print(\"Mayor accuracy promedio con:\",type_kernel[parametros[0]],parameter_C[parametros[1]])\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparacin entre SVM y MLP implementado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
